{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, accuracy_score, balanced_accuracy_score\n",
    "from base import *\n",
    "from config import *\n",
    "from mne.beamformer import make_lcmv, apply_lcmv_epochs\n",
    "from collections import defaultdict\n",
    "from scipy.stats import ttest_1samp, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from jax import jit, grad, vmap, device_put, random\n",
    "import jax.numpy as jnp\n",
    "from jax.lib import xla_bridge\n",
    "from functools import partial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/preprocessed/stim/sub01_0_s-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -196.61 ...     599.65 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5679"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params\n",
    "trial_types = [\"all\", \"pattern\", \"random\"]\n",
    "trial_type = 'pattern'\n",
    "data_path = DATA_DIR\n",
    "lock = \"stim\"\n",
    "subjects = SUBJS\n",
    "sessions = ['practice', 'b1', 'b2', 'b3', 'b4']\n",
    "subjects_dir = FREESURFER_DIR\n",
    "res_path = RESULTS_DIR\n",
    "folds = 2\n",
    "chance = 0.5\n",
    "threshold = 0.05\n",
    "scoring = \"accuracy\"\n",
    "scoring = \"roc_auc\"\n",
    "parc='aparc'\n",
    "hemi = 'both'\n",
    "params = \"pred_decoding\"\n",
    "verbose = True\n",
    "jobs = -1\n",
    "decim = True\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# figures dir\n",
    "figures = RESULTS_DIR / 'figures' / lock / params / 'source' / trial_type\n",
    "ensure_dir(figures)\n",
    "# get times\n",
    "epoch_fname = DATA_DIR / lock / 'sub01_0_s-epo.fif'\n",
    "epochs = mne.read_epochs(epoch_fname, verbose=verbose)\n",
    "times = epochs.times\n",
    "if decim:\n",
    "    times = times[::3]\n",
    "del epochs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 34 labels from /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/freesurfer/sub01/label/lh.aparc.annot\n",
      "   read 34 labels from /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/freesurfer/sub01/label/rh.aparc.annot\n",
      "Reading /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/preprocessed/stim/sub01_0_s-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -196.61 ...     599.65 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading forward solution from /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/results/fwd/stim/sub01-fwd-0.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_27169/1439677120.py:24: RuntimeWarning: This filename (/Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/results/fwd/stim/sub01-fwd-0.fif) does not conform to MNE naming conventions. All forward files should end with -fwd.fif, -fwd.fif.gz, _fwd.fif, _fwd.fif.gz, -fwd.h5 or _fwd.h5\n",
      "  fwd = mne.read_forward_solution(fwd_fname, verbose=verbose)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (8196 sources, 246 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 246 after 0 projectors applied to 246 channels\n",
      "Reducing data rank from 246 -> 246\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Number of samples used : 14145\n",
      "[done]\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 246 after 0 projectors applied to 246 channels\n",
      "Reducing data rank from 246 -> 246\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Number of samples used : 4715\n",
      "[done]\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 1e-13 (2.2e-16 eps * 246 dim * 1.9  max singular value)\n",
      "    Estimated rank (mag): 243\n",
      "    MAG: rank 243 computed from 246 data channels with 0 projectors\n",
      "Computing rank from covariance with rank={'mag': 243}\n",
      "Computing rank from covariance with rank={'mag': 243}\n",
      "Making LCMV beamformer with rank {'mag': 243}\n",
      "Computing inverse operator with 246 channels.\n",
      "    246 out of 246 channels remain after picking\n",
      "Selected 246 channels\n",
      "Whitening the forward solution.\n",
      "Computing rank from covariance with rank={'mag': 243}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing beamformer filters for 8196 sources\n",
      "Filter computation complete\n",
      "Processing epoch : 1\n",
      "combining the current components...\n",
      "Processing epoch : 2\n",
      "combining the current components...\n",
      "Processing epoch : 3\n",
      "combining the current components...\n",
      "Processing epoch : 4\n",
      "combining the current components...\n",
      "Processing epoch : 5\n",
      "combining the current components...\n",
      "Processing epoch : 6\n",
      "combining the current components...\n",
      "Processing epoch : 7\n",
      "combining the current components...\n",
      "Processing epoch : 8\n",
      "combining the current components...\n",
      "Processing epoch : 9\n",
      "combining the current components...\n",
      "Processing epoch : 10\n",
      "combining the current components...\n",
      "Processing epoch : 11\n",
      "combining the current components...\n",
      "Processing epoch : 12\n",
      "combining the current components...\n",
      "Processing epoch : 13\n",
      "combining the current components...\n",
      "Processing epoch : 14\n",
      "combining the current components...\n",
      "Processing epoch : 15\n",
      "combining the current components...\n",
      "Processing epoch : 16\n",
      "combining the current components...\n",
      "Processing epoch : 17\n",
      "combining the current components...\n",
      "Processing epoch : 18\n",
      "combining the current components...\n",
      "Processing epoch : 19\n",
      "combining the current components...\n",
      "Processing epoch : 20\n",
      "combining the current components...\n",
      "Processing epoch : 21\n",
      "combining the current components...\n",
      "Processing epoch : 22\n",
      "combining the current components...\n",
      "Processing epoch : 23\n",
      "combining the current components...\n",
      "Processing epoch : 24\n",
      "combining the current components...\n",
      "Processing epoch : 25\n",
      "combining the current components...\n",
      "Processing epoch : 26\n",
      "combining the current components...\n",
      "Processing epoch : 27\n",
      "combining the current components...\n",
      "Processing epoch : 28\n",
      "combining the current components...\n",
      "Processing epoch : 29\n",
      "combining the current components...\n",
      "Processing epoch : 30\n",
      "combining the current components...\n",
      "Processing epoch : 31\n",
      "combining the current components...\n",
      "Processing epoch : 32\n",
      "combining the current components...\n",
      "Processing epoch : 33\n",
      "combining the current components...\n",
      "Processing epoch : 34\n",
      "combining the current components...\n",
      "Processing epoch : 35\n",
      "combining the current components...\n",
      "Processing epoch : 36\n",
      "combining the current components...\n",
      "Processing epoch : 37\n",
      "combining the current components...\n",
      "Processing epoch : 38\n",
      "combining the current components...\n",
      "Processing epoch : 39\n",
      "combining the current components...\n",
      "Processing epoch : 40\n",
      "combining the current components...\n",
      "Processing epoch : 41\n",
      "combining the current components...\n",
      "Processing epoch : 42\n",
      "combining the current components...\n",
      "Processing epoch : 43\n",
      "combining the current components...\n",
      "Processing epoch : 44\n",
      "combining the current components...\n",
      "Processing epoch : 45\n",
      "combining the current components...\n",
      "Processing epoch : 46\n",
      "combining the current components...\n",
      "Processing epoch : 47\n",
      "combining the current components...\n",
      "Processing epoch : 48\n",
      "combining the current components...\n",
      "Processing epoch : 49\n",
      "combining the current components...\n",
      "Processing epoch : 50\n",
      "combining the current components...\n",
      "Processing epoch : 51\n",
      "combining the current components...\n",
      "Processing epoch : 52\n",
      "combining the current components...\n",
      "Processing epoch : 53\n",
      "combining the current components...\n",
      "Processing epoch : 54\n",
      "combining the current components...\n",
      "Processing epoch : 55\n",
      "combining the current components...\n",
      "Processing epoch : 56\n",
      "combining the current components...\n",
      "Processing epoch : 57\n",
      "combining the current components...\n",
      "Processing epoch : 58\n",
      "combining the current components...\n",
      "Processing epoch : 59\n",
      "combining the current components...\n",
      "Processing epoch : 60\n",
      "combining the current components...\n",
      "Processing epoch : 61\n",
      "combining the current components...\n",
      "Processing epoch : 62\n",
      "combining the current components...\n",
      "Processing epoch : 63\n",
      "combining the current components...\n",
      "Processing epoch : 64\n",
      "combining the current components...\n",
      "Processing epoch : 65\n",
      "combining the current components...\n",
      "Processing epoch : 66\n",
      "combining the current components...\n",
      "Processing epoch : 67\n",
      "combining the current components...\n",
      "Processing epoch : 68\n",
      "combining the current components...\n",
      "Processing epoch : 69\n",
      "combining the current components...\n",
      "Processing epoch : 70\n",
      "combining the current components...\n",
      "Processing epoch : 71\n",
      "combining the current components...\n",
      "Processing epoch : 72\n",
      "combining the current components...\n",
      "Processing epoch : 73\n",
      "combining the current components...\n",
      "Processing epoch : 74\n",
      "combining the current components...\n",
      "Processing epoch : 75\n",
      "combining the current components...\n",
      "Processing epoch : 76\n",
      "combining the current components...\n",
      "Processing epoch : 77\n",
      "combining the current components...\n",
      "Processing epoch : 78\n",
      "combining the current components...\n",
      "Processing epoch : 79\n",
      "combining the current components...\n",
      "Processing epoch : 80\n",
      "combining the current components...\n",
      "Processing epoch : 81\n",
      "combining the current components...\n",
      "Processing epoch : 82\n",
      "combining the current components...\n",
      "Processing epoch : 83\n",
      "combining the current components...\n",
      "Processing epoch : 84\n",
      "combining the current components...\n",
      "Processing epoch : 85\n",
      "combining the current components...\n",
      "Processing epoch : 86\n",
      "combining the current components...\n",
      "Processing epoch : 87\n",
      "combining the current components...\n",
      "Processing epoch : 88\n",
      "combining the current components...\n",
      "Processing epoch : 89\n",
      "combining the current components...\n",
      "Processing epoch : 90\n",
      "combining the current components...\n",
      "Processing epoch : 91\n",
      "combining the current components...\n",
      "Processing epoch : 92\n",
      "combining the current components...\n",
      "Processing epoch : 93\n",
      "combining the current components...\n",
      "Processing epoch : 94\n",
      "combining the current components...\n",
      "Processing epoch : 95\n",
      "combining the current components...\n",
      "Processing epoch : 96\n",
      "combining the current components...\n",
      "Processing epoch : 97\n",
      "combining the current components...\n",
      "Processing epoch : 98\n",
      "combining the current components...\n",
      "Processing epoch : 99\n",
      "combining the current components...\n",
      "Processing epoch : 100\n",
      "combining the current components...\n",
      "Processing epoch : 101\n",
      "combining the current components...\n",
      "Processing epoch : 102\n",
      "combining the current components...\n",
      "Processing epoch : 103\n",
      "combining the current components...\n",
      "Processing epoch : 104\n",
      "combining the current components...\n",
      "Processing epoch : 105\n",
      "combining the current components...\n",
      "Processing epoch : 106\n",
      "combining the current components...\n",
      "Processing epoch : 107\n",
      "combining the current components...\n",
      "Processing epoch : 108\n",
      "combining the current components...\n",
      "Processing epoch : 109\n",
      "combining the current components...\n",
      "Processing epoch : 110\n",
      "combining the current components...\n",
      "Processing epoch : 111\n",
      "combining the current components...\n",
      "Processing epoch : 112\n",
      "combining the current components...\n",
      "Processing epoch : 113\n",
      "combining the current components...\n",
      "Processing epoch : 114\n",
      "combining the current components...\n",
      "Processing epoch : 115\n",
      "combining the current components...\n",
      "[done]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = subjects[0]\n",
    "# get labels\n",
    "labels = mne.read_labels_from_annot(subject=subject, parc=parc, hemi=hemi, subjects_dir=subjects_dir, verbose=verbose)\n",
    "# label = labels[ilabel]\n",
    "        \n",
    "session_id, session = 0, sessions[0]\n",
    "# read stim epoch\n",
    "epoch_fname = data_path / lock / f\"{subject}_{session_id}_s-epo.fif\"\n",
    "epoch = mne.read_epochs(epoch_fname, preload=True, verbose=True)\n",
    "# read behav\n",
    "behav_fname = data_path / \"behav\" / f\"{subject}_{session_id}.pkl\"\n",
    "behav = pd.read_pickle(behav_fname).reset_index()    \n",
    "# get session behav and epoch\n",
    "if session_id == 0:\n",
    "    session = 'prac'\n",
    "else:\n",
    "    session = 'sess-%s' % (str(session_id).zfill(2))\n",
    "\n",
    "if lock == 'button': \n",
    "    epoch_bsl_fname = data_path / \"bsl\" / f\"{subject}_{session_id}_bl-epo.fif\"\n",
    "    epoch_bsl = mne.read_epochs(epoch_bsl_fname, verbose=verbose)\n",
    "# read forward solution    \n",
    "fwd_fname = res_path / \"fwd\" / lock / f\"{subject}-fwd-{session_id}.fif\"\n",
    "fwd = mne.read_forward_solution(fwd_fname, verbose=verbose)\n",
    "# compute data covariance matrix on evoked data\n",
    "data_cov = mne.compute_covariance(epoch, tmin=0, tmax=.6, method=\"empirical\", rank=\"info\", verbose=verbose)\n",
    "# compute noise covariance\n",
    "if lock == 'button':\n",
    "    noise_cov = mne.compute_covariance(epoch_bsl, method=\"empirical\", rank=\"info\", verbose=verbose)\n",
    "else:\n",
    "    noise_cov = mne.compute_covariance(epoch, tmin=-.2, tmax=0, method=\"empirical\", rank=\"info\", verbose=verbose)\n",
    "info = epoch.info\n",
    "# conpute rank\n",
    "rank = mne.compute_rank(noise_cov, info=info, rank=None, tol_kind='relative', verbose=verbose)\n",
    "# compute source estimate\n",
    "filters = make_lcmv(info, fwd, data_cov=data_cov, noise_cov=noise_cov,\n",
    "                pick_ori=None, rank=rank, reduce_rank=True, verbose=verbose)\n",
    "stcs = apply_lcmv_epochs(epoch, filters=filters, verbose=verbose)\n",
    "\n",
    "del epoch, fwd, data_cov, noise_cov, rank, filters\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/68 sub01 prac bankssts-lh\n",
      "X shape: (51, 47, 55) (trials, vertices, time points)\n"
     ]
    }
   ],
   "source": [
    "ilabel, label = 0, labels[0]\n",
    "print(f\"{ilabel+1}/{len(labels)}\", subject, session, label.name)\n",
    "\n",
    "# get stcs in label\n",
    "stcs_data = [stc.in_label(label).data for stc in stcs]\n",
    "stcs_data = np.array(stcs_data)\n",
    "assert len(stcs_data) == len(behav)\n",
    "\n",
    "if trial_type == 'pattern':\n",
    "    pattern = behav.trialtypes == 1\n",
    "    X = stcs_data[pattern]\n",
    "    y = behav.positions[pattern]\n",
    "elif trial_type == 'random':\n",
    "    random = behav.trialtypes == 2\n",
    "    X = stcs_data[random]\n",
    "    y = behav.positions[random]\n",
    "else:\n",
    "    X = stcs_data\n",
    "    y = behav.positions\n",
    "y = y.reset_index(drop=True).to_numpy()            \n",
    "assert X.shape[0] == y.shape[0]\n",
    "\n",
    "if decim:                 \n",
    "    X = X[:, :, ::3]\n",
    "\n",
    "print(\"X shape:\", X.shape, \"(trials, vertices, time points)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (2475, 47)\n",
      "y_train shape:  (2475,)\n",
      "X_test shape:  (330, 47)\n",
      "y_test shape:  (330,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.1, random_state=42)\n",
    "X_train = X_train.swapaxes(1, 2)\n",
    "X_train = X_train.reshape(-1, X_train.shape[-1])\n",
    "\n",
    "X_test = X_test.swapaxes(1, 2)\n",
    "X_test_original = X_test.copy()\n",
    "X_test = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "y_train = y_train.repeat(X.shape[-1]) - 1\n",
    "y_test = y_test.repeat(X.shape[-1]) - 1\n",
    "y_test_original = y_test.copy()\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit,grad,vmap,device_put,random\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "class JaxReg:\n",
    "    \"\"\"\n",
    "    Logistic regression classifier with GPU acceleration support through Google's JAX. The point of this class is fitting speed: I want this\n",
    "    to fit a model for very large datasets (k49 in particular) as quickly as possible!\n",
    "\n",
    "    - jit compilation utilized in sigma and loss methods (strongest in sigma due to matrix mult.). We need to 'partial' the\n",
    "      jit function because it is used within a class.\n",
    "\n",
    "    - jax.numpy (jnp) operations are JAX implementations of numpy functions.\n",
    "\n",
    "    - jax.grad used as the gradient function. Returns gradient with respect to first parameter.\n",
    "\n",
    "    - jax.vmap is used to 'vectorize' the jax.grad function. Used to compute gradient of batch elements at once, in parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate=.001, num_epochs=50, size_batch=20):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.size_batch = size_batch\n",
    "\n",
    "    def fit(self, data, y):\n",
    "        self.K = max(y) + 1\n",
    "        ones = jnp.ones((data.shape[0], 1))\n",
    "        X = jnp.concatenate((ones, data), axis=1)\n",
    "        W = jnp.zeros((jnp.shape(X)[1], max(y) + 1))\n",
    "\n",
    "        self.coeff = self.mb_gd(W, X, y)\n",
    "\n",
    "    # New mini-batch gradient descent function (because jitted functions require arrays which do not change shape)\n",
    "    def mb_gd(self, W, X, y):\n",
    "        num_epochs = self.num_epochs\n",
    "        size_batch = self.size_batch\n",
    "        eta = self.learning_rate\n",
    "        N = X.shape[0]\n",
    "\n",
    "        # Define the gradient function using jit, vmap, and the jax's own gradient function, grad.\n",
    "        # vmap is especially useful for mini-batch GD since we compute all gradients of the batch at once, in parallel.\n",
    "        # Special paramaters in_axes,out_axes define the axis of the input paramters (W, X, y) and output (gradients of batches)\n",
    "        # upon which to vectorize. grads_b = loss_grad(W, X_batch, y_batch) has shape (batch_size, p+1, k) for p variables and k classes.\n",
    "\n",
    "        loss_grad = jit(vmap(grad(self.loss), in_axes=(None, 0, 0), out_axes=0))\n",
    "\n",
    "        for e in range(num_epochs):\n",
    "            shuffle_index = random.permutation(random.PRNGKey(e), N)\n",
    "            for m in range(0, N, size_batch):\n",
    "                i = shuffle_index[m:m + size_batch]\n",
    "\n",
    "                grads_b = loss_grad(W, X[i, :], y[i])  # 3D jax array of size (batch_size, p+1, k): gradients for each batch element\n",
    "\n",
    "                W -= eta * jnp.mean(grads_b, axis=0)  # Update W with average over each batch\n",
    "        return W\n",
    "\n",
    "    def predict(self, data):\n",
    "        ones = jnp.ones((data.shape[0], 1))\n",
    "        X = jnp.concatenate((ones, data), axis=1)  # Augment to account for intercept\n",
    "        W = self.coeff\n",
    "        y_pred = jnp.argmax(self.sigma(X, W),\n",
    "                            axis=1)  # Predicted class is largest probability returned by softmax array\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, data, y_true):\n",
    "        ones = jnp.ones((data.shape[0], 1))\n",
    "        X = jnp.concatenate((ones, data), axis=1)\n",
    "        y_pred = self.predict(data)\n",
    "        acc = jnp.mean(y_pred == y_true)\n",
    "        return acc\n",
    "\n",
    "    # jitting 'sigma' is the biggest speed-up compared to the original implementation\n",
    "    @partial(jit, static_argnums=0)\n",
    "    def sigma(self, X, W):\n",
    "        if X.ndim == 1:\n",
    "            X = jnp.reshape(X, (-1, X.shape[0]))  # jax.grad seems to necessitate a reshape: X -> (1,p+1)\n",
    "        s = jnp.exp(jnp.matmul(X, W))\n",
    "        total = jnp.sum(s, axis=1).reshape(-1, 1)\n",
    "        return s / total\n",
    "\n",
    "    @partial(jit, static_argnums=0)\n",
    "    def loss(self, W, X, y):\n",
    "        f_value = self.sigma(X, W)\n",
    "        loss_vector = jnp.zeros(X.shape[0])\n",
    "        for k in range(self.K):\n",
    "            loss_vector += jnp.log(f_value + 1e-10)[:, k] * (y == k)\n",
    "        return -jnp.mean(loss_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METAL\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: /var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_27169/560624563.py:86:0: error: failed to legalize operation 'mhlo.scatter'\n/var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_27169/560624563.py:52:0: note: called from\n/var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_27169/560624563.py:86:0: note: see current operation: \n%90 = \"mhlo.scatter\"(%11, %7, %89) ({\n^bb0(%arg3: tensor<f32>, %arg4: tensor<f32>):\n  \"mhlo.return\"(%arg4) : (tensor<f32>) -> ()\n}) {indices_are_sorted = true, scatter_dimension_numbers = #mhlo.scatter<update_window_dims = [0, 1, 2], scatter_dims_to_operand_dims = [1, 2]>, unique_indices = true} : (tensor<254x1x4xf32>, tensor<2xsi32>, tensor<254x1x1xf32>) -> tensor<254x1x4xf32>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m y_train_dp \u001b[38;5;241m=\u001b[39m device_put(y_train)\n\u001b[1;32m     11\u001b[0m lg_sgd_jax \u001b[38;5;241m=\u001b[39m JaxReg(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, size_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m254\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mlg_sgd_jax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_dp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_dp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m, in \u001b[0;36mJaxReg.fit\u001b[0;34m(self, data, y)\u001b[0m\n\u001b[1;32m     28\u001b[0m X \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mconcatenate((ones, data), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m W \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros((jnp\u001b[38;5;241m.\u001b[39mshape(X)[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mmax\u001b[39m(y) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoeff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmb_gd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 52\u001b[0m, in \u001b[0;36mJaxReg.mb_gd\u001b[0;34m(self, W, X, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, N, size_batch):\n\u001b[1;32m     50\u001b[0m         i \u001b[38;5;241m=\u001b[39m shuffle_index[m:m \u001b[38;5;241m+\u001b[39m size_batch]\n\u001b[0;32m---> 52\u001b[0m         grads_b \u001b[38;5;241m=\u001b[39m \u001b[43mloss_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 3D jax array of size (batch_size, p+1, k): gradients for each batch element\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         W \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m eta \u001b[38;5;241m*\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(grads_b, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Update W with average over each batch\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/fidle/lib/python3.9/site-packages/jax/_src/dispatch.py:465\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    461\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: /var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_27169/560624563.py:86:0: error: failed to legalize operation 'mhlo.scatter'\n/var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_27169/560624563.py:52:0: note: called from\n/var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_27169/560624563.py:86:0: note: see current operation: \n%90 = \"mhlo.scatter\"(%11, %7, %89) ({\n^bb0(%arg3: tensor<f32>, %arg4: tensor<f32>):\n  \"mhlo.return\"(%arg4) : (tensor<f32>) -> ()\n}) {indices_are_sorted = true, scatter_dimension_numbers = #mhlo.scatter<update_window_dims = [0, 1, 2], scatter_dims_to_operand_dims = [1, 2]>, unique_indices = true} : (tensor<254x1x4xf32>, tensor<2xsi32>, tensor<254x1x1xf32>) -> tensor<254x1x4xf32>\n"
     ]
    }
   ],
   "source": [
    "from jax.lib import xla_bridge\n",
    "\n",
    "# Find fitting times for JaxReg models using 20 epochs\n",
    "\n",
    "print(xla_bridge.get_backend().platform) # Confirm GPU in use\n",
    "\n",
    "# Commit data to device - note these are now JAX arrays. Type: jaxlib.xla_extension.DeviceArray\n",
    "X_train_dp = device_put(X_train)\n",
    "y_train_dp = device_put(y_train)\n",
    "\n",
    "lg_sgd_jax = JaxReg(learning_rate=1e-6, num_epochs = 20, size_batch = X_train_dp.shape[0])\n",
    "lg_sgd_jax.fit(X_train_dp, y_train_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lg_sgd_jax.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
