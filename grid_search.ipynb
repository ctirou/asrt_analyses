{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore, CSP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from base import ensure_dir\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = DATA_DIR\n",
    "subjects, epochs_list = SUBJS, EPOCHS\n",
    "lock = 'stim'\n",
    "figures = op.join(RESULTS_DIR, 'figures', lock, 'decoding')\n",
    "ensure_dir(figures)\n",
    "\n",
    "res_path = op.join(figures, 'slide_stim', 'grid+LR')\n",
    "ensure_dir(res_path)\n",
    "\n",
    "gdf_fname = op.join(figures, \"grid_search_results\")\n",
    "ensure_dir(gdf_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "1135 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coum/anaconda3/envs/mnex/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'logisticregression__C': 0.01, 'logisticregression__solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_5680/2369065409.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best[\"subject\"] = subject\n",
      "/var/folders/y_/m3qn82z15yb4fhdtdwn9vp_h0000gq/T/ipykernel_5680/2369065409.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  best[\"subject\"] = subject\n"
     ]
    }
   ],
   "source": [
    "gen_df = pd.DataFrame()\n",
    "\n",
    "for subject in subjects[:1]:\n",
    "        \n",
    "    all_epochs = list()\n",
    "    all_behavs = list()\n",
    "    \n",
    "    for epoch_num, epo in enumerate(epochs_list):\n",
    "\n",
    "        behav = pd.read_pickle(op.join(data_path, 'behav', f'{subject}_{epoch_num}.pkl'))\n",
    "        epoch_fname = op.join(data_path, \"%s/%s_%s_s-epo.fif\" % (lock, subject, epoch_num))\n",
    "        epoch = mne.read_epochs(epoch_fname, verbose=\"error\")\n",
    "        times = epoch.times\n",
    "                \n",
    "        all_epochs.append(epoch)\n",
    "        all_behavs.append(behav)\n",
    "    \n",
    "    for epoch in all_epochs: # see mne.preprocessing.maxwell_filter to realign the runs to a common head position. On raw data.\n",
    "        epoch.info['dev_head_t'] = all_epochs[0].info['dev_head_t']\n",
    "    \n",
    "    epochs = mne.concatenate_epochs(all_epochs)\n",
    "    behav_df = pd.concat(all_behavs)\n",
    "            \n",
    "        \n",
    "    # 1 ---------- Perform grid search on entire dataset ---------------------\n",
    "        \n",
    "    X = epochs.pick_types(meg=True, stim=False, ref_meg=False)._data\n",
    "    y = np.array(behav_df['positions'])\n",
    "\n",
    "    pca = UnsupervisedSpatialFilter(PCA(100), average=False)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_reshaped = X_pca.reshape(X_pca.shape[0], -1)\n",
    "    \n",
    "    param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "                  'logisticregression__solver': ['liblinear', 'lbfgs']}\n",
    "                #   'logisticregression__penalty': ['l2', 'l1', 'elasticnet']}\n",
    "\n",
    "    clf_pipeline = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)) # LR > LDA, lSVC, rbf-SVC\n",
    "    grid_search = GridSearchCV(clf_pipeline, param_grid, cv=KFold(3), scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_reshaped, y)\n",
    "    \n",
    "    grid_df = pd.DataFrame(grid_search.cv_results_).sort_values(by=[\"rank_test_score\"])\n",
    "    grid_df.to_csv(op.join(gdf_fname, \"%s.csv\" % subject ), index=False)\n",
    "    \n",
    "    best = grid_df.iloc[0]\n",
    "    best[\"subject\"] = subject\n",
    "    gen_df = pd.concat([gen_df, best], ignore_index=False)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    \n",
    "    # 2 ---------- Use best params for sliding window ---------------------\n",
    "    \n",
    "    # window_length = 0.1  # time window in s\n",
    "    # spacing = 0.05  # sliding period in s\n",
    "    # times, scores = list(), list()\n",
    "    \n",
    "    # best_params = {key.replace('logisticregression__', ''): value for key, value in best_params.items()}\n",
    "    # clf = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, **best_params)) # LR > LDA, lSVC, rbf-SVC\n",
    "\n",
    "    # for time in np.arange(epochs.tmin, epochs.tmax - window_length, spacing):\n",
    "    #     tt = np.where((epochs.times >= time) & (epochs.times < time + window_length))[0]\n",
    "    #     xx = X_pca[:, :, tt]\n",
    "    #     xx = xx.reshape(xx.shape[0], xx.shape[1]*xx.shape[2])\n",
    "    #     score = cross_val_multiscore(clf_pipeline, xx, y, cv=KFold(10)).mean()\n",
    "    #     times.append(time + window_length/2.)\n",
    "    #     scores.append(score)\n",
    "        \n",
    "    # plt.plot(times, scores)\n",
    "    # plt.title(max(scores))\n",
    "    # plt.savefig(op.join(res_path, \"%s\" % subject))\n",
    "    # plt.close()\n",
    "\n",
    "gen_df = gen_df.T\n",
    "gen_df.to_csv(op.join(gdf_fname, \"gen_grid.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
