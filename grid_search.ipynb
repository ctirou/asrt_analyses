{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore, CSP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from base import ensure_dir\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_pca = False\n",
    "\n",
    "data_path = DATA_DIR\n",
    "subjects, epochs_list = SUBJS, EPOCHS\n",
    "lock = 'stim'\n",
    "figures = op.join(RESULTS_DIR, 'figures', lock, 'decoding')\n",
    "ensure_dir(figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/preprocessed/stim/sub01_0_s-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -196.61 ...     599.65 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/preprocessed/stim/sub01_1_s-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -196.61 ...     599.65 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "244 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/preprocessed/stim/sub01_2_s-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -196.61 ...     599.65 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "253 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/preprocessed/stim/sub01_3_s-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -196.61 ...     599.65 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "269 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /Users/coum/Library/CloudStorage/OneDrive-etu.univ-lyon1.fr/asrt/preprocessed/stim/sub01_4_s-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -196.61 ...     599.65 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "254 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "1135 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters: {'logisticregression__C': 0.01, 'logisticregression__solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "for subject in subjects[:1]:\n",
    "        \n",
    "    all_epochs = list()\n",
    "    all_behavs = list()\n",
    "    \n",
    "    for epoch_num, epo in enumerate(epochs_list):\n",
    "\n",
    "        behav = pd.read_pickle(op.join(data_path, 'behav', f'{subject}_{epoch_num}.pkl'))\n",
    "        epoch_fname = op.join(data_path, \"%s/%s_%s_s-epo.fif\" % (lock, subject, epoch_num))\n",
    "        epoch = mne.read_epochs(epoch_fname)\n",
    "        times = epoch.times\n",
    "                \n",
    "        all_epochs.append(epoch)\n",
    "        all_behavs.append(behav)\n",
    "    \n",
    "    for epoch in all_epochs: # see mne.preprocessing.maxwell_filter to realign the runs to a common head position. On raw data.\n",
    "        epoch.info['dev_head_t'] = all_epochs[0].info['dev_head_t']\n",
    "    \n",
    "    epochs = mne.concatenate_epochs(all_epochs)\n",
    "    behav_df = pd.concat(all_behavs)\n",
    "            \n",
    "        \n",
    "    # 1 ---------- Perform grid search on entire dataset ---------------------\n",
    "    \n",
    "    res_path = op.join(figures, 'slide_stim', 'grid+LR')\n",
    "    ensure_dir(res_path)\n",
    "    \n",
    "    X = epochs.pick_types(meg=True, stim=False, ref_meg=False)._data\n",
    "    y = np.array(behav_df['positions'])\n",
    "\n",
    "    pca = UnsupervisedSpatialFilter(PCA(100), average=False)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_reshaped = X_pca.reshape(X_pca.shape[0], -1)\n",
    "    \n",
    "    param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "                  'logisticregression__solver': ['liblinear', 'lbfgs']}\n",
    "\n",
    "    clf_pipeline = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000)) # LR > LDA, lSVC, rbf-SVC\n",
    "    grid_search = GridSearchCV(clf_pipeline, param_grid, cv=KFold(3), scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_reshaped, y)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    \n",
    "    # 2 ---------- Use best params for sliding window ---------------------\n",
    "    \n",
    "    window_length = 0.1  # time window in s\n",
    "    spacing = 0.05  # sliding period in s\n",
    "    times, scores = list(), list()\n",
    "    \n",
    "    best_params = {key.replace('logisticregression__', ''): value for key, value in best_params.items()}\n",
    "    clf = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, **best_params)) # LR > LDA, lSVC, rbf-SVC\n",
    "\n",
    "    for time in np.arange(epochs.tmin, epochs.tmax - window_length, spacing):\n",
    "        tt = np.where((epochs.times >= time) & (epochs.times < time + window_length))[0]\n",
    "        xx = X_pca[:, :, tt]\n",
    "        xx = xx.reshape(xx.shape[0], xx.shape[1]*xx.shape[2])\n",
    "        score = cross_val_multiscore(clf_pipeline, xx, y, cv=KFold(3)).mean()\n",
    "        times.append(time + window_length/2.)\n",
    "        scores.append(score)\n",
    "        \n",
    "    plt.plot(times, scores)\n",
    "    plt.title(max(scores))\n",
    "    plt.savefig(op.join(res_path, \"%s\" % subject))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
